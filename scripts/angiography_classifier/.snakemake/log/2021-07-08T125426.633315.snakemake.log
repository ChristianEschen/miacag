Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Job stats:
job           count    min threads    max threads
----------  -------  -------------  -------------
preprocess        1              1              1
total             1              1              1


[Thu Jul  8 12:54:26 2021]
rule preprocess:
    input: /home/gandalf/MIA/data/angio/pre_train.csv, /home/gandalf/MIA/data/angio/pre_val.csv, /home/gandalf/MIA/data/angio
    output: /home/gandalf/MIA/data/angio/train.csv, /home/gandalf/MIA/data/angio/val.csv, /home/gandalf/MIA/data/angio/minc_file_path
    jobid: 0
    resources: tmpdir=/tmp

Skipped removing non-empty directory /home/gandalf/MIA/data/angio/minc_file_path
[Thu Jul  8 12:54:27 2021]
Error in rule preprocess:
    jobid: 0
    output: /home/gandalf/MIA/data/angio/train.csv, /home/gandalf/MIA/data/angio/val.csv, /home/gandalf/MIA/data/angio/minc_file_path
    shell:
        
        python ../../preprocessing/pre_process.py \
        --train_csv_files /home/gandalf/MIA/data/angio/pre_train.csv \
        --val_csv_files /home/gandalf/MIA/data/angio/pre_val.csv \
        --input_data_root /home/gandalf/MIA/data/angio \
        --output_train_csv /home/gandalf/MIA/data/angio/train.csv \
        --output_val_csv /home/gandalf/MIA/data/angio/val.csv \
        --output_data_root /home/gandalf/MIA/data/angio/minc_file_path \
        --num_workers 2 \
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job preprocess since they might be corrupted:
/home/gandalf/MIA/data/angio/minc_file_path
Skipped removing non-empty directory /home/gandalf/MIA/data/angio/minc_file_path
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/gandalf/MIA/scripts/angiography_classifier/.snakemake/log/2021-07-08T125426.633315.snakemake.log
