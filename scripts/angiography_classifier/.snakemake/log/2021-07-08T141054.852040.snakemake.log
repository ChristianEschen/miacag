Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Job stats:
job            count    min threads    max threads
-----------  -------  -------------  -------------
all                1              1              1
preprocess         1              1              1
train_model        1              1              1
total              3              1              1


[Thu Jul  8 14:10:54 2021]
rule preprocess:
    input: /home/gandalf/MIA/data/angio/pre_train.csv, /home/gandalf/MIA/data/angio/pre_val.csv, /home/gandalf/MIA/data/angio
    output: /home/gandalf/MIA/data/angio/train.csv, /home/gandalf/MIA/data/angio/val.csv, /home/gandalf/MIA/data/angio/minc_file_path
    jobid: 1
    resources: tmpdir=/tmp

[Thu Jul  8 14:10:56 2021]
Error in rule preprocess:
    jobid: 1
    output: /home/gandalf/MIA/data/angio/train.csv, /home/gandalf/MIA/data/angio/val.csv, /home/gandalf/MIA/data/angio/minc_file_path
    shell:
        
        python ../../preprocessing/pre_process.py \
        --train_csv_files /home/gandalf/MIA/data/angio/pre_train.csv \
        --val_csv_files /home/gandalf/MIA/data/angio/pre_val.csv \
        --input_data_root /home/gandalf/MIA/data/angio \
        --output_train_csv /home/gandalf/MIA/data/angio/train.csv \
        --output_val_csv /home/gandalf/MIA/data/angio/val.csv \
        --output_data_root /home/gandalf/MIA/data/angio/minc_file_path \
        --num_workers 2 
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job preprocess since they might be corrupted:
/home/gandalf/MIA/data/angio/train.csv, /home/gandalf/MIA/data/angio/val.csv, /home/gandalf/MIA/data/angio/minc_file_path
Terminating processes on user request, this might take some time.
Complete log: /home/gandalf/MIA/scripts/angiography_classifier/.snakemake/log/2021-07-08T141054.852040.snakemake.log
