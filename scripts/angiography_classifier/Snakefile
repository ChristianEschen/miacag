import uuid
import os

# inputs:
train_csv_files = "/home/gandalf/MIA/data/angio/pre_train.csv"
val_csv_files = "/home/gandalf/MIA/data/angio/pre_val.csv"
input_data_root = "/home/gandalf/MIA/data/angio/"

# outputs 
output_train_csv = "/home/gandalf/MIA/data/angio/train.csv"
output_val_csv = "/home/gandalf/MIA/data/angio/val.csv"
output_data_root = "/home/gandalf/MIA/data/angio/minc_file_path/"
# temp outputs
logfile = os.path.join('runs', str(uuid.uuid4())) + '.log'
logfile_test = os.path.join('runs', str(uuid.uuid4())) + '.log'


# params
num_workers = workflow.cores
nproc_per_node = 1
nnodes = 1
node_rank = 0
master_addr = "192.168.8.116"
master_port = 1234
cpu = "False"
config_train = "/home/gandalf/MIA/configs/classification/_3D/classification_config_train_nifty_angio.yaml"
config_test = "/home/gandalf/MIA/configs/classification/_3D/classification_config_test_nifty_angio.yaml"


rule all:
    input:
        output_train_csv,
        output_val_csv,
        output_data_root,
        logfile,
        logfile_test

# feature extract

rule preprocess:
    input:
        train_csv_files = train_csv_files,
        val_csv_files = val_csv_files,
        input_data_root = input_data_root
    output:
        output_train_csv = output_train_csv,
        output_val_csv = output_val_csv,
        output_data_root = directory(output_data_root)
    params:
        num_workers = num_workers
    shell:
        """
        python ../../preprocessing/pre_process.py \\
        --train_csv_files {input.train_csv_files} \\
        --val_csv_files {input.val_csv_files} \\
        --input_data_root {input.input_data_root} \\
        --output_train_csv {output.output_train_csv} \\
        --output_val_csv {output.output_val_csv} \\
        --output_data_root {output.output_data_root} \\
        --num_workers {params.num_workers} 
        """

rule train_model:
    input:
        TraindataRoot = output_data_root,
        TraindataCSV = output_train_csv,
        ValdataRoot = output_data_root,
        ValdataCSV = output_val_csv
    output:
        logfile = temp(logfile)
    params:
        num_workers = num_workers,
        nproc_per_node = nproc_per_node,
        nnodes = nnodes,
        node_rank = node_rank,
        master_addr = master_addr,
        master_port = master_port,
        cpu = cpu,
        config = config_train
    shell:
       """
       python -m torch.distributed.launch \\
       --nproc_per_node {params.nproc_per_node} \\
       --nnodes {params.nnodes} \\
       --node_rank {params.node_rank} \\
       --master_addr {params.master_addr} \\
       --master_port {params.master_port} \\
       ../../trainer.py \\
       --config {params.config} \\
       --TraindataRoot {input.TraindataRoot} \\
       --TraindataCSV {input.TraindataCSV} \\
       --ValdataRoot {input.ValdataRoot} \\
       --ValdataCSV {input.ValdataCSV} \\
       --cpu {params.cpu} \\
       --num_workers {params.num_workers} \\
       --logfile {output.logfile}
       """

rule test_model:
    input:
        ValdataRoot = output_data_root,
        ValdataCSV = output_val_csv,
        logfile = logfile
    output:
        logfile_test = temp(logfile_test)
    params:
        config = config_test,
        num_workers = num_workers,
    shell:
        """
        python ../../tester.py \\
        --config {params.config} \\
        --num_workers {params.num_workers}
        --ValdataRoot {input.ValdataRoot} \\
        --ValdataCSV {input.ValdataCSV} \\
        --logfile {input.logfile} \\
        ; touch {output.logfile_test}
        """
