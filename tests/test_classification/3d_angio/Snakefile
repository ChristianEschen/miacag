import uuid
import os
import socket

# inputs:
train_csv_files =  ["../../../data/angio/pre_train.csv"]
val_csv_files = ["../../../data/angio/pre_val.csv"]

# outputs 
output_train_csv = "../../../data/angio/train.csv"
output_val_csv = "../../../data/angio/val.csv"
output_data_root = "../../../data/angio/minc_file_path/"
# temp outputs
logfile = os.path.join('runs', str(uuid.uuid4())) + '.log'
logfile_test = os.path.join('runs', str(uuid.uuid4())) + '.log'
config_file_temp = os.path.join('runs', str(uuid.uuid4())) + '.yaml'



# params
num_workers = workflow.cores
nproc_per_node = 1
nnodes = 1
node_rank = 0
master_addr = socket.gethostbyname(socket.gethostname())
master_port = 1234
cpu = "True"
config_train = "/home/sauroman/mia/configs/classification/_3D/classification_config_train_nifty_angio.yaml"
tensorboard_comment = 'test'

rule all:
    input:
        output_train_csv,
        output_val_csv,
        config_file_temp,
        output_data_root,
        logfile,
        logfile_test

# feature extract

rule preprocess:
    input:
        train_csv_files = train_csv_files,
        val_csv_files = val_csv_files,
        config_train = config_train
    output:
        output_train_csv = output_train_csv,
        output_val_csv = output_val_csv,
        output_data_root = directory(output_data_root),
        config_file_temp = temp(config_file_temp)
    params:
        num_workers = num_workers
    shell:
        """
        python ../../../preprocessing/pre_process.py \\
        --train_csv_files {input.train_csv_files} \\
        --val_csv_files {input.val_csv_files} \\
        --output_train_csv {output.output_train_csv} \\
        --output_val_csv {output.output_val_csv} \\
        --output_data_root {output.output_data_root} \\
        --num_workers {params.num_workers} \\
        ; cp {input.config_train} {output.config_file_temp}
        """

rule train_model:
    input:
        TraindataRoot = output_data_root,
        TraindataCSV = output_train_csv,
        ValdataRoot = output_data_root,
        ValdataCSV = output_val_csv
    output:
        logfile = temp(logfile)
    params:
        num_workers = num_workers,
        nproc_per_node = nproc_per_node,
        nnodes = nnodes,
        node_rank = node_rank,
        master_addr = master_addr,
        master_port = master_port,
        cpu = cpu,
        config = temp(config_file_temp),
        tensorboard_comment = tensorboard_comment
    shell:
       """
       python -m torch.distributed.launch \\
       --nproc_per_node {params.nproc_per_node} \\
       --nnodes {params.nnodes} \\
       --node_rank {params.node_rank} \\
       --master_addr {params.master_addr} \\
       --master_port {params.master_port} \\
       ../../trainer.py \\
       --config {params.config} \\
       --TraindataRoot {input.TraindataRoot} \\
       --TraindataCSV {input.TraindataCSV} \\
       --ValdataRoot {input.ValdataRoot} \\
       --ValdataCSV {input.ValdataCSV} \\
       --cpu {params.cpu} \\
       --num_workers {params.num_workers} \\
       --logfile {output.logfile} \\
       --tensorboard_comment {params.tensorboard_comment}
       """

rule test_model:
    input:
        ValdataRoot = output_data_root,
        ValdataCSV = output_val_csv,
        logfile = logfile
    output:
        logfile_test = temp(logfile_test)
    params:
        num_workers = num_workers,
    shell:
        """
        python ../../tester.py \\
        --num_workers {params.num_workers} \\
        --ValdataRoot {input.ValdataRoot} \\
        --ValdataCSV {input.ValdataCSV} \\
        --logfile {input.logfile} \\
        ; touch {output.logfile_test}
        """
