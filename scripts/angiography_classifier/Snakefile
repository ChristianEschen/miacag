
import uuid
import os
import socket
from datetime import datetime
import yaml

# params

config_path = "../../configs/classification/_3D/classification_config_angio.yaml"
num_workers = workflow.cores
master_addr = socket.gethostbyname(socket.gethostname())

def mkFolder(dir):
    os.makedirs(dir, exist_ok=True)


with open(config_path) as file:
    config = yaml.load(file, Loader=yaml.FullLoader)
print('config', config)
tensorboard_comment = 'test'
experiment_name = datetime.now().strftime('%b%d_%H-%M-%S') + \
            '_' + socket.gethostname() + tensorboard_comment
output_directory = os.path.join(
            config['output'],
            experiment_name)
mkFolder(output_directory)
output_model = os.path.join(output_directory, "model.pt")

output_table_name = config['table_name'] + "_" + experiment_name

output_plots = os.path.join(output_directory, 'plots')
mkFolder(output_plots)

output_plots_train = os.path.join(output_plots, 'train')
output_plots_val = os.path.join(output_plots, 'val')
output_plots_test = os.path.join(output_plots, 'test')


mkFolder(output_plots_train)
mkFolder(output_plots_test)
mkFolder(output_plots_val)

# temp outputs
tempfile_table_copy_inp = os.path.join('runs', str(uuid.uuid4())) + '.log'
tempfile_table_copy_out = os.path.join('runs', str(uuid.uuid4())) + '.log'

tempfile_split_train_val = os.path.join('runs', str(uuid.uuid4())) + '.log'

logfile_val = os.path.join('runs', str(uuid.uuid4())) + '.log'
logfile_test = os.path.join('runs', str(uuid.uuid4())) + '.log'

config_file_temp = os.path.join('runs', str(uuid.uuid4())) + '.yaml'

logfile_plot_train = os.path.join('runs', str(uuid.uuid4())) + '.log'
logfile_plot_test = os.path.join('runs', str(uuid.uuid4())) + '.log'
logfile_plot_val = os.path.join('runs', str(uuid.uuid4())) + '.log'


rule all:
    input:
        tempfile_table_copy_out,
        config_file_temp,
        output_model,
        logfile_val,
        logfile_plot_train,
        logfile_plot_val,
        logfile_plot_test


rule copy_table:
    input:
        output_directory = output_directory
    output:
        tempfile_table_copy_out = temp(tempfile_table_copy_out)
    params:
        username = config['username'],
        password = config['password'],
        database = config['database'],
        host = config['host'],
        table_name = config['table_name'],
        output_table_name = output_table_name

    shell:
        """
        mkdir -p {input.output_directory} \\
        ; python ../../preprocessing/copy_table.py \\
            --database {params.database} \\
            --username {params.username} \\
            --password {params.password} \\
            --host {params.host} \\
            --table_name_input {params.table_name} \\
            --table_name_output {params.output_table_name} \\
        ; touch {output.tempfile_table_copy_out}
        """

rule copy_config:
    input:
        config_path = config_path
    output:
        config_file_temp = temp(config_file_temp)

    shell:
        """
        cp {input.config_path} {output.config_file_temp}
        """

rule split_train_val:
    input:
        config = config_file_temp,
        output_directory = output_directory,
        tempfile_table_copy_out = tempfile_table_copy_out
    output:
        tempfile_split_train_val = tempfile_split_train_val
    params:
        query = config['query'],
        username = config['username'],
        password = config['password'],
        database = config['database'],
        TestSize = config['TestSize'],
        host = config['host'],
        output_table_name = output_table_name
    shell:
       """
       python ../../preprocessing/split_train_val.py \\
       --config {input.config} \\
       --database {params.database} \\
       --username {params.username} \\
       --password {params.password} \\
       --host {params.host} \\
       --table_name {params.output_table_name} \\
       --query "{params.query}" \\
       --TestSize {params.TestSize} \\
       ; touch {output.tempfile_split_train_val}
       """


rule train_model:
    input:
        DataSetPath = config['DataSetPath'],
        config = config_file_temp,
        output_directory = output_directory,
        tempfile_table_copy_out = tempfile_table_copy_out,
        tempfile_split_train_val = tempfile_split_train_val
    output:
        output_model = output_model
    params:
        query = config['query'],
        num_workers = num_workers,
        nproc_per_node = config['nproc_per_node'],
        nnodes = config['nnodes'],
        node_rank = config['node_rank'],
        master_addr = master_addr,
        master_port = config['master_port'],
        cpu = config['cpu'],
        username = config['username'],
        password = config['password'],
        database = config['database'],
        host = config['host'],
        output_table_name = output_table_name
    shell:
       """
       NCCL_DEBUG=info \\
       python -m torch.distributed.launch \\
       --nproc_per_node {params.nproc_per_node} \\
       --nnodes {params.nnodes} \\
       --node_rank {params.node_rank} \\
       --master_addr {params.master_addr} \\
       --master_port {params.master_port} \\
       ../../trainer.py \\
       --config {input.config} \\
       --DataSetPath {input.DataSetPath} \\
       --output_directory {input.output_directory} \\
       --database {params.database} \\
       --username {params.username} \\
       --password {params.password} \\
       --host {params.host} \\
       --table_name {params.output_table_name} \\
       --query "{params.query}" \\
       --cpu {params.cpu} \\
       --num_workers {params.num_workers}
       """

rule eval_model_val_set:
    input:
        DataSetPath = config['DataSetPath'],
        output_directory = output_directory,
        out = rules.train_model.output.output_model
    output:
        logfile_val = temp(logfile_val)
    params:
        num_workers = 0,
        cpu = config['cpu'],
        query_test = config['query_test'],
        test_size = 1,
        username = config['username'],
        password = config['password'],
        database = config['database'],
        host = config['host'],
        output_table_name = output_table_name,
        nproc_per_node = config['nproc_per_node'],
        nnodes = config['nnodes'],
        node_rank = config['node_rank'],
        master_addr = master_addr,
        master_port = config['master_port'],
        use_DDP = "False"
    shell:
        """
        python -m torch.distributed.launch \\
        --nproc_per_node {params.nproc_per_node} \\
        --nnodes {params.nnodes} \\
        --node_rank {params.node_rank} \\
        --master_addr {params.master_addr} \\
        --master_port {params.master_port} \\
       ../../tester.py \\
       --num_workers {params.num_workers} \\
       --DataSetPath {input.DataSetPath} \\
       --output_directory {input.output_directory} \\
       --database {params.database} \\
       --username {params.username} \\
       --password {params.password} \\
       --host {params.host} \\
       --table_name {params.output_table_name} \\
       --query "{params.query_test}" \\
       --cpu {params.cpu} \\
       --TestSize {params.test_size} \\
       --use_DDP {params.use_DDP} \\
       ; touch {output.logfile_val} \\
        """

rule plot_results_train:
    input:
        out = rules.eval_model_val_set.output.logfile_val,
        output_plots_train = output_plots_train
    output:
        logfile_plot_train = temp(logfile_plot_train)
    params:
        output_table_name = output_table_name,
        query = config['query_train_plot'],
        username = config['username'],
        password = config['password'],
        database = config['database'],
        host = config['host']
    shell:
        """
        mkdir -p {input.output_plots_train} \\
        ; Rscript ../../plots/plotter.r \\
        {input.output_plots_train} \\
        {params.output_table_name} \\
        "{params.query}" \\
        {params.username} \\
        {params.password} \\
        {params.host} \\
        {params.database} \\
        ; touch {output.logfile_plot_train} \\
        """

rule plot_results_val:
    input:
        out = rules.eval_model_val_set.output.logfile_val,
        output_plots_val = output_plots_val
    output:
        logfile_plot_val = temp(logfile_plot_val)
    params:
        output_table_name = output_table_name,
        query = config['query_val_plot'],
        username = config['username'],
        password = config['password'],
        database = config['database'],
        host = config['host']
    shell:
        """
        mkdir -p {input.output_plots_val} \\
        ; Rscript ../../plots/plotter.r \\
        {input.output_plots_val} \\
        {params.output_table_name} \\
        "{params.query}" \\
        {params.username} \\
        {params.password} \\
        {params.host} \\
        {params.database} \\
        ; touch {output.logfile_plot_val} \\
        """

rule plot_results_test:
    input:
        out = rules.eval_model_val_set.output.logfile_val,
        output_plots_test = output_plots_test
    output:
        logfile_plot_test = temp(logfile_plot_test)
    params:
        output_table_name = output_table_name,
        query = config['query_test_plot'],
        username = config['username'],
        password = config['password'],
        database = config['database'],
        host = config['host']
    shell:
        """
        mkdir -p {input.output_plots_test} \\
        ; Rscript ../../plots/plotter.r \\
        {input.output_plots_test} \\
        {params.output_table_name} \\
        "{params.query}" \\
        {params.username} \\
        {params.password} \\
        {params.host} \\
        {params.database} \\
        ; touch {output.logfile_plot_test} \\
        """
